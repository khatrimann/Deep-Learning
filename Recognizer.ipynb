{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./digit-recognizer/train.csv')\n",
    "test = pd.read_csv('./digit-recognizer/test.csv')\n",
    "target = train.iloc[:, 0].values\n",
    "train = train.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train = sc.fit_transform(train)\n",
    "test = sc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=784, units=397, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=397,  init='uniform', activation='relu', input_dim=784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=397, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=397, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=397, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=397, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=397,  init='uniform', activation='relu'))\n",
    "classifier.add(Dense(output_dim=397,  init='uniform', activation='relu'))\n",
    "classifier.add(Dense(output_dim=397,  init='uniform', activation='relu'))\n",
    "classifier.add(Dense(output_dim=397,  init='uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=10, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=10,  init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 17s 415us/step - loss: 0.3245 - acc: 0.9026\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 17s 395us/step - loss: 0.1329 - acc: 0.9623\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 17s 407us/step - loss: 0.0896 - acc: 0.9742\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 16s 377us/step - loss: 0.0710 - acc: 0.9802\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 17s 397us/step - loss: 0.0543 - acc: 0.9847\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 16s 377us/step - loss: 0.0512 - acc: 0.9856\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 16s 376us/step - loss: 0.0436 - acc: 0.9879\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 16s 374us/step - loss: 0.0464 - acc: 0.9884\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 16s 379us/step - loss: 0.0387 - acc: 0.9897\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 16s 379us/step - loss: 0.0368 - acc: 0.9903\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 16s 383us/step - loss: 0.0340 - acc: 0.9915\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 16s 385us/step - loss: 0.0308 - acc: 0.9930\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 16s 382us/step - loss: 0.0321 - acc: 0.9920\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 18s 432us/step - loss: 0.0260 - acc: 0.9936\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 17s 409us/step - loss: 0.0274 - acc: 0.9935\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 16s 378us/step - loss: 0.0202 - acc: 0.9951\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 16s 370us/step - loss: 0.0274 - acc: 0.9934\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 15s 357us/step - loss: 0.0248 - acc: 0.9945\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 15s 369us/step - loss: 0.0417 - acc: 0.9837\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 17s 396us/step - loss: 0.0293 - acc: 0.9935\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 15s 352us/step - loss: 0.0316 - acc: 0.9927\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 15s 361us/step - loss: 0.0218 - acc: 0.9953\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 15s 363us/step - loss: 0.0186 - acc: 0.9957\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 0.0193 - acc: 0.9954\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 0.0251 - acc: 0.9945\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 15s 352us/step - loss: 0.0251 - acc: 0.9945\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 0.0267 - acc: 0.9954\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 15s 364us/step - loss: 0.0198 - acc: 0.9959\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 15s 357us/step - loss: 0.0248 - acc: 0.9949\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 17s 405us/step - loss: 0.0224 - acc: 0.9954\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 17s 402us/step - loss: 0.0214 - acc: 0.9956\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 18s 423us/step - loss: 0.0291 - acc: 0.9947\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 18s 438us/step - loss: 0.0460 - acc: 0.9930\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 19s 447us/step - loss: 0.0327 - acc: 0.9932\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 18s 420us/step - loss: 0.0332 - acc: 0.9931\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 19s 463us/step - loss: 0.0322 - acc: 0.9929\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 19s 461us/step - loss: 0.0385 - acc: 0.9930\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 16s 390us/step - loss: 0.0397 - acc: 0.9929\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 16s 385us/step - loss: 0.0308 - acc: 0.9942\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 16s 392us/step - loss: 0.0817 - acc: 0.9811\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 16s 390us/step - loss: 0.0604 - acc: 0.9894\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 16s 392us/step - loss: 0.1442 - acc: 0.9822\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 16s 392us/step - loss: 0.0877 - acc: 0.9813\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 16s 390us/step - loss: 0.0625 - acc: 0.9906\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 16s 390us/step - loss: 0.0661 - acc: 0.9880\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 16s 392us/step - loss: 0.0686 - acc: 0.9867\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 17s 397us/step - loss: 0.1244 - acc: 0.9748\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 17s 397us/step - loss: 0.1346 - acc: 0.9761\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 17s 395us/step - loss: 0.0737 - acc: 0.9882\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 17s 397us/step - loss: 0.1285 - acc: 0.9775\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 16s 392us/step - loss: 0.2503 - acc: 0.9524\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 17s 404us/step - loss: 0.1959 - acc: 0.9587\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 16s 384us/step - loss: 0.3590 - acc: 0.9211\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 16s 382us/step - loss: 0.2824 - acc: 0.9453\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 16s 386us/step - loss: 0.2772 - acc: 0.8818\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 16s 382us/step - loss: 0.3211 - acc: 0.8871\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 16s 383us/step - loss: 0.4335 - acc: 0.8480\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 16s 386us/step - loss: 0.3614 - acc: 0.8869\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 16s 389us/step - loss: 0.3308 - acc: 0.9390\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 16s 385us/step - loss: 0.2804 - acc: 0.9388\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 16s 384us/step - loss: 0.4058 - acc: 0.9005\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 16s 383us/step - loss: 0.5203 - acc: 0.8702\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 16s 385us/step - loss: 0.6302 - acc: 0.8824\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 16s 383us/step - loss: 1.5938 - acc: 0.4322\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 16s 383us/step - loss: 1.7579 - acc: 0.3780\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 16s 383us/step - loss: 1.6261 - acc: 0.3816\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 16s 385us/step - loss: 1.6751 - acc: 0.4421\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 16s 387us/step - loss: 1.2615 - acc: 0.5560\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 18s 419us/step - loss: 1.2154 - acc: 0.4931\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 16s 390us/step - loss: 1.1798 - acc: 0.5363\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 16s 391us/step - loss: 1.4375 - acc: 0.4379\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 16s 389us/step - loss: 1.7063 - acc: 0.2708\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 17s 408us/step - loss: 1.4724 - acc: 0.3750\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 17s 393us/step - loss: 1.5534 - acc: 0.4528\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 16s 390us/step - loss: 1.3618 - acc: 0.4587\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 16s 388us/step - loss: 1.7906 - acc: 0.5372\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 16s 386us/step - loss: 1.5907 - acc: 0.4974\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 17s 411us/step - loss: 1.9104 - acc: 0.4783\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 16s 382us/step - loss: 2.1475 - acc: 0.3781\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 15s 352us/step - loss: 2.6521 - acc: 0.3880\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 15s 353us/step - loss: 2.7913 - acc: 0.3130\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 15s 354us/step - loss: 1.9518 - acc: 0.2671\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 15s 353us/step - loss: 2.1883 - acc: 0.1360\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 15s 354us/step - loss: 2.2544 - acc: 0.1763\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 15s 353us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 15s 352us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 15s 354us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 15s 352us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 15s 353us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 15s 349us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 15s 365us/step - loss: 2.2568 - acc: 0.1764\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 15s 360us/step - loss: 2.2568 - acc: 0.1764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ad4b15a58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train, target, batch_size=100, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
